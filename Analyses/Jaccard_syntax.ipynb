{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cleared-assignment",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [15, 6]\n",
    "from pandas import DataFrame\n",
    "import lang2vec.lang2vec as l2v\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "future-magnet",
   "metadata": {},
   "source": [
    "## Jaccard Similarity (Jmm_syn)\n",
    "\n",
    "1. Functions for calculating Jaccard's similarity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "elementary-breakfast",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict(arg1,arg2,arg3,sourcedata): #it returns a dataframe with bins and a dictionary {region:number of languages} based on the source data (measures)\n",
    "  min=arg1\n",
    "  max=arg2\n",
    "  increment=arg3\n",
    "  #np.lin... loadspace(min,max,24)\n",
    "  bins=np.arange(min, max, increment)\n",
    "  #clc_10k\n",
    "  data_regions = pd.DataFrame(columns=['Avg_length', 'Median_length', 'Char_types', 'Types','Tokens','TTR','H','region'])\n",
    "\n",
    "  data_regions_freq=dict()\n",
    "  for i in bins:\n",
    "    aux=pd.DataFrame(sourcedata.loc[(sourcedata['Avg_length']>i) & (sourcedata['Avg_length']<(i+increment))])\n",
    "    region=str(i)+\"-\"+str(i+increment)\n",
    "    data_regions_freq[region]=len(aux)  #hash with the number of elements per each region\n",
    "    aux['region']=region\n",
    "    data_regions= pd.concat([data_regions, aux], axis=0)\n",
    "\n",
    "  return (data_regions, data_regions_freq)\n",
    "################################\n",
    "def scaler1(data1, data2): #Input two dictionaries  {bin:number of languages}, it returns an scaled version (each dictionary is normalized indepedently)\n",
    "  a=np.array(list(data1.values())).sum()\n",
    "  b=np.array(list(data2.values())).sum()\n",
    "  scaled=dict()\n",
    "  if (a>b):\n",
    "    max=a\n",
    "    min=b\n",
    "    c=max/min\n",
    "    for key in data2:  #we apply constant c to the set with smallest cardinality \n",
    "      scaled[key]=data2[key]*c\n",
    "    return(data1, scaled)\n",
    "  else:\n",
    "    max=b\n",
    "    min=a\n",
    "    c=max/min\n",
    "    for key in data1:  #we apply constant c to the set with smallest cardinality \n",
    "      scaled[key]=data1[key]*c\n",
    "    return(scaled, data2)\n",
    "\n",
    "###################################################\n",
    "def jaccard_index(data1, data2): # Input two dictionaries  {bin:number of languages}\n",
    "  union=dict()\n",
    "  intersection=dict()\n",
    "  intersectionvalues=[]\n",
    "  unionvalues=[]\n",
    "  for key in data1: #both dics have the same keys\n",
    "  #first define the union, for each class/bin choose the one with the highest value\n",
    "    if (data1[key] > data2[key]):\n",
    "      union[key]=data1[key]\n",
    "      unionvalues.append(union[key])\n",
    "      \n",
    "    else:\n",
    "      union[key]=data2[key]\n",
    "      unionvalues.append(union[key])\n",
    "\n",
    "    \n",
    "  #Then the intersection: which  have both  values, choose the smallest \n",
    "    if (data1[key] !=0) and (data2[key]!=0):\n",
    "      if (data1[key] < data2[key]):\n",
    "        intersection[key]=data1[key]\n",
    "        intersectionvalues.append(intersection[key])\n",
    "      else:\n",
    "        intersection[key]=data2[key]\n",
    "        intersectionvalues.append(intersection[key])\n",
    "\n",
    "  jaccard=np.array(intersectionvalues).sum()/np.array(unionvalues).sum()\n",
    "      \n",
    "  return(jaccard, union, intersection, unionvalues, intersectionvalues)\n",
    "\n",
    "###################################3\n",
    "def draw_overlap_plot(frame1,frame2,label1,label2, list1, list2):  \n",
    "  frame1.columns=[label1]\n",
    "  frame2.columns=[label2]\n",
    "  col1=frame1  #from here we'll make barplot 1\n",
    "  col2=frame2 #from here we'll make barplot 2\n",
    "  #Preparing subplot:\n",
    "  fig, ax = plt.subplots()\n",
    "  ax2 = ax.twinx()\n",
    "  plot1=col1.plot(kind='bar', ax=ax, color='orange', width=1, align=\"edge\", alpha=0.4)\n",
    "  plot2=col2.plot(kind='bar', ax=ax2, alpha=0.5,width=1, color='palegreen', align=\"edge\")\n",
    "  positions = (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,12)  #fixed for now, imporve later\n",
    "  labels = (\"1\", \"2\", \"3\", \"4\", \"5\", \"6\",\"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\") #fixed for now, improve later\n",
    "\n",
    "  plt.setp(ax, xticks= positions, xticklabels=labels)\n",
    "  ax.tick_params(labelrotation=0, labelsize=12)\n",
    "  ax2.tick_params(labelsize=12)\n",
    "  ax.legend(fontsize=14)\n",
    "  ax2.legend([label2], loc=('upper left'), fontsize=14)\n",
    "\n",
    "  ax2.xaxis.set_visible(False)\n",
    "  #ax.set_ylim(ax2.get_ylim())\n",
    "  ax.set_ylim(top=50)  #set fixed axis\n",
    "  ax2.set_ylim(top=50)  #set fixed axis\n",
    "\n",
    "  ax.set_xlabel('Mean word length', fontsize=14)\n",
    "\n",
    "  ###We Print Jaccard's score in the plot:\n",
    "\n",
    "  jacc=jaccard_index(list1,list2)[0]  #Jaccard's index (scaling2)\n",
    "  textstr=\"J=\"+str(round(jacc,3))\n",
    "  plt.gcf().text(0.5, 0.8, textstr, fontsize=14)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatty-collapse",
   "metadata": {},
   "source": [
    "2. Obtain syntax feature vectors form lang2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "monetary-george",
   "metadata": {},
   "outputs": [],
   "source": [
    "xcopa_codes=pd.read_csv('../Data/isomappings/xcopa-processed.10000.csv', index_col=0)\n",
    "xquad_codes=pd.read_csv('../Data/isomappings/xquad-processed.10000.csv', index_col=0)\n",
    "tydiqa_codes=pd.read_csv('../Data/isomappings/tydiqa-processed.10000.csv', index_col=0)\n",
    "xnli_codes=pd.read_csv('../Data/isomappings/xnli-processed.10000.csv', index_col=0)\n",
    "xtreme_codes=pd.read_csv('../Data/isomappings/xtreme-processed.10000.csv', index_col=0)\n",
    "xglue_codes=pd.read_csv('../Data/isomappings/xglue-processed.10000.csv', index_col=0)\n",
    "ud_codes=pd.read_csv('../Data/isomappings/ud-processed.tsv', sep='\\t', index_col=0)\n",
    "teddi_codes=pd.read_csv('../Data/isomappings/teddi500.csv', index_col=0)\n",
    "mbert_codes=pd.read_csv('../Data/isomappings/mbertwiki-processed.10000.csv', index_col=0)\n",
    "bible_codes=pd.read_csv('../Data/isomappings/biblecorpus100-processed.10000.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "small-negotiation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#manual substitutions for problematic cases\n",
    "ud_codes.loc[\"UD_Western_Armenian-ArmTDP.txt\"].at[\"ISO_6393\"]=\"hy\"\n",
    "mbert_codes.loc[\"armenian\"].at[\"ISO_6393\"]=\"hy\"\n",
    "mbert_codes.loc[\"vowiki-latest-pages-articles\"].at[\"ISO_6393\"]=\"vol\"\n",
    "bible_codes=bible_codes.drop([\"crp.txt\"])\n",
    "bible_codes.loc[\"jap.txt\"].at[\"ISO_6393\"]=\"jpn\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "connected-funeral",
   "metadata": {},
   "source": [
    "Function for exracting the vectors according to the language codes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "artificial-burke",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_l2v(dataset_codes):\n",
    "    #list of iso codes to query the l2v vectors:\n",
    "    codes=dataset_codes[\"ISO_6393\"].str.lower().tolist()\n",
    "    #codes=xcopa_codes.index.tolist()\n",
    "    \n",
    "    features = l2v.get_features(codes, \"syntax_knn\")\n",
    "    #features = l2v.get_features(codes, \"syntax_average\")\n",
    "\n",
    "    features_frame = pd.DataFrame.from_dict(features).transpose()\n",
    "    return (features_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "front-japan",
   "metadata": {},
   "source": [
    "Addapting to the variables names, so we can run the jaccard's code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "attractive-ivory",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clc_10k_freqs=get_l2v(teddi_codes).sum().to_frame() #We obtain the sum per each column (feature), these are feature and frequency pairs\n",
    "df_xcopa_10k_freqs=get_l2v(xcopa_codes).sum().to_frame()\n",
    "df_xquad_10k_freqs=get_l2v(xquad_codes).sum().to_frame()\n",
    "df_tydiqa_10k_freqs=get_l2v(tydiqa_codes).sum().to_frame()\n",
    "df_xnli_10k_freqs=get_l2v(xnli_codes).sum().to_frame()\n",
    "df_xtreme_10k_freqs=get_l2v(xtreme_codes).sum().to_frame()\n",
    "df_xglue_10k_freqs=get_l2v(xglue_codes).sum().to_frame()\n",
    "df_ud_10k_freqs=get_l2v(ud_codes).sum().to_frame()\n",
    "df_mbert_10k_freqs=get_l2v(mbert_codes).sum().to_frame()\n",
    "df_bibles_10k_freqs=get_l2v(bible_codes).sum().to_frame()\n",
    "\n",
    "bibles_10k_freqs=get_l2v(bible_codes).sum().to_dict()\n",
    "clc_10k_freqs=get_l2v(teddi_codes).sum().to_dict()\n",
    "xcopa_10k_freqs=get_l2v(xcopa_codes).sum().to_dict()\n",
    "xquad_10k_freqs=get_l2v(xquad_codes).sum().to_dict()\n",
    "tydiqa_10k_freqs=get_l2v(tydiqa_codes).sum().to_dict()\n",
    "xnli_10k_freqs=get_l2v(xnli_codes).sum().to_dict()\n",
    "xtreme_10k_freqs=get_l2v(xtreme_codes).sum().to_dict()\n",
    "xglue_10k_freqs=get_l2v(xglue_codes).sum().to_dict()\n",
    "ud_10k_freqs=get_l2v(ud_codes).sum().to_dict()\n",
    "mbert_10k_freqs=get_l2v(mbert_codes).sum().to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustained-tunisia",
   "metadata": {
    "id": "nHV6PVS2u54u"
   },
   "source": [
    "---\n",
    "\n",
    "\n",
    "**Teddi (100LC) vs UD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "based-performer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling1 #Basic normalization (dividing by the number of languages) ~probabilities\n",
    "ud_10k_freqs_norm1, clc_10k_freqs_norm1=scaler1(ud_10k_freqs,clc_10k_freqs)\n",
    "df_clc_10k_freqs_norm1=pd.DataFrame.from_dict(clc_10k_freqs_norm1, orient='index')\n",
    "df_ud_10k_freqs_norm1=pd.DataFrame.from_dict(ud_10k_freqs_norm1, orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacterial-height",
   "metadata": {
    "id": "e-wmZR48eLsl"
   },
   "source": [
    "Jaccard's schore between Teddi and UD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "normal-conversion",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Nl0CZ-iuEtk",
    "outputId": "55b3bc1f-8a62-499e-a038-38230f5f7ff1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard's index (no scaling) 0.6545731044970672\n",
      "Jaccard's index (scaling1) 0.736327204327871\n"
     ]
    }
   ],
   "source": [
    "print(\"Jaccard's index (no scaling)\", jaccard_index(ud_10k_freqs,clc_10k_freqs)[0])\n",
    "print(\"Jaccard's index (scaling1)\", jaccard_index(ud_10k_freqs_norm1,clc_10k_freqs_norm1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certain-contributor",
   "metadata": {
    "id": "KoZFeNxJEXWQ"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**100 BIBLE CORPUS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "tamil-thirty",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing1:\n",
    "bibles_10k_freqs_norm1, clc_10k_freqs_norm1=scaler1(get_l2v(bible_codes).sum().to_dict(),get_l2v(teddi_codes).sum().to_dict())\n",
    "df_clc_10k_freqs_norm1=pd.DataFrame.from_dict(clc_10k_freqs_norm1, orient='index')\n",
    "df_bibles_10k_freqs_norm1=pd.DataFrame.from_dict(bibles_10k_freqs_norm1, orient='index')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separate-framing",
   "metadata": {
    "id": "nHV6PVS2u54u"
   },
   "source": [
    "Jaccard score between 100 Bible corpus and 100LC :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "crucial-elizabeth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard's index (no scaling) 0.7575830524795378\n",
      "Jaccard's index (scaling1) 0.8109984079295679\n"
     ]
    }
   ],
   "source": [
    "print(\"Jaccard's index (no scaling)\", jaccard_index(bibles_10k_freqs,clc_10k_freqs)[0])\n",
    "print(\"Jaccard's index (scaling1)\", jaccard_index(bibles_10k_freqs_norm1,clc_10k_freqs_norm1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharp-romantic",
   "metadata": {
    "id": "F_zawS5xjG1K"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**XCOPA**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "interracial-drill",
   "metadata": {
    "id": "x6DM87k0jpTv"
   },
   "outputs": [],
   "source": [
    "#normalizing1:\n",
    "xcopa_10k_freqs_norm1, clc_10k_freqs_norm1=scaler1(xcopa_10k_freqs,clc_10k_freqs)\n",
    "df_clc_10k_freqs_norm1=pd.DataFrame.from_dict(clc_10k_freqs_norm1, orient='index')\n",
    "df_xcopa_10k_freqs_norm1=pd.DataFrame.from_dict(xcopa_10k_freqs_norm1, orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imposed-hypothetical",
   "metadata": {
    "id": "Sk_7eXHUkYJ-"
   },
   "source": [
    "Jaccard score between Xcopa corpus and 100LC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "superior-effect",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sZUz5RYmkYJ_",
    "outputId": "dbe03277-fd05-4abd-9c87-ebfa64e3bd9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard's index (no scaling) 0.1189767995240928\n",
      "Jaccard's index (scaling1) 0.7367013445714917\n"
     ]
    }
   ],
   "source": [
    "print(\"Jaccard's index (no scaling)\", jaccard_index(xcopa_10k_freqs,clc_10k_freqs)[0])\n",
    "print(\"Jaccard's index (scaling1)\", jaccard_index(xcopa_10k_freqs_norm1,clc_10k_freqs_norm1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-verse",
   "metadata": {
    "id": "uXcgcai-2Iww"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**TyDiQA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "greater-cheat",
   "metadata": {
    "id": "amg9GayN2n_m"
   },
   "outputs": [],
   "source": [
    "df_tydiqa_10k_freqs=pd.DataFrame.from_dict(tydiqa_10k_freqs, orient='index')\n",
    "#normalizing1:\n",
    "tydiqa_10k_freqs_norm1, clc_10k_freqs_norm1=scaler1(tydiqa_10k_freqs,clc_10k_freqs)\n",
    "df_clc_10k_freqs_norm1=pd.DataFrame.from_dict(clc_10k_freqs_norm1, orient='index')\n",
    "df_tydiqa_10k_freqs_norm1=pd.DataFrame.from_dict(tydiqa_10k_freqs_norm1, orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generic-armstrong",
   "metadata": {
    "id": "h11nqQwVfKK6"
   },
   "source": [
    "Jaccard's score between 100LC and TydiQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "burning-aviation",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IOhFCrY03Mhn",
    "outputId": "99ec39f9-9ab7-4ce5-d9a9-a8cebf1b1df3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard's index (no scaling) 0.12526033918476645\n",
      "Jaccard's index (scaling1) 0.7512151925836588\n"
     ]
    }
   ],
   "source": [
    "print(\"Jaccard's index (no scaling)\", jaccard_index(tydiqa_10k_freqs,clc_10k_freqs)[0])\n",
    "print(\"Jaccard's index (scaling1)\", jaccard_index(tydiqa_10k_freqs_norm1,clc_10k_freqs_norm1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recreational-creativity",
   "metadata": {
    "id": "AHi27NOghkjt"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "**XQUAD**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "criminal-radio",
   "metadata": {
    "id": "7Mr81TBDihMe"
   },
   "outputs": [],
   "source": [
    "#normalizing1:\n",
    "xquad_10k_freqs_norm1, clc_10k_freqs_norm1=scaler1(xquad_10k_freqs,clc_10k_freqs)\n",
    "df_clc_10k_freqs_norm1=pd.DataFrame.from_dict(clc_10k_freqs_norm1, orient='index')\n",
    "df_xquad_10k_freqs_norm1=pd.DataFrame.from_dict(xquad_10k_freqs_norm1, orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "substantial-prayer",
   "metadata": {
    "id": "r0ActI8gfSgI"
   },
   "source": [
    "Jaccard's score between 100LC and Xquad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "unavailable-treasure",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z4JlSJx9i8O3",
    "outputId": "5aee9dd2-b1fc-4b93-c67f-bfce66df28f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard's index (no scaling) 0.1430696014277216\n",
      "Jaccard's index (scaling1) 0.68042417173084\n"
     ]
    }
   ],
   "source": [
    "print(\"Jaccard's index (no scaling)\", jaccard_index(xquad_10k_freqs,clc_10k_freqs)[0])\n",
    "print(\"Jaccard's index (scaling1)\", jaccard_index(xquad_10k_freqs_norm1,clc_10k_freqs_norm1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equal-enclosure",
   "metadata": {
    "id": "1DScTV_TQwGn"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "**XNLI**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "pacific-norman",
   "metadata": {
    "id": "j3A9gjx0UHyJ"
   },
   "outputs": [],
   "source": [
    "#normalizing1:\n",
    "xnli_10k_freqs_norm1, clc_10k_freqs_norm1=scaler1(xnli_10k_freqs,clc_10k_freqs)\n",
    "df_clc_10k_freqs_norm1=pd.DataFrame.from_dict(clc_10k_freqs_norm1, orient='index')\n",
    "df_xnli_10k_freqs_norm1=pd.DataFrame.from_dict(xnli_10k_freqs_norm1, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "excessive-composition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard's index (no scaling) 0.17846519928613921\n",
      "Jaccard's index (scaling1) 0.7105759671292086\n"
     ]
    }
   ],
   "source": [
    "print(\"Jaccard's index (no scaling)\", jaccard_index(xnli_10k_freqs,clc_10k_freqs)[0])\n",
    "print(\"Jaccard's index (scaling1)\", jaccard_index(xnli_10k_freqs_norm1,clc_10k_freqs_norm1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convertible-trinidad",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "**XGLUE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "painful-dodge",
   "metadata": {
    "id": "fhKx--19aX22"
   },
   "outputs": [],
   "source": [
    "\n",
    "#normalizing1:\n",
    "xglue_10k_freqs_norm1, clc_10k_freqs_norm1=scaler1(xglue_10k_freqs,clc_10k_freqs)\n",
    "df_clc_10k_freqs_norm1=pd.DataFrame.from_dict(clc_10k_freqs_norm1, orient='index')\n",
    "df_xglue_10k_freqs_norm1=pd.DataFrame.from_dict(xglue_10k_freqs_norm1, orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radical-albany",
   "metadata": {
    "id": "wELlX08VfdOC"
   },
   "source": [
    "Jaccard's score between 100LC and Xglue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "crucial-spokesman",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E8SBhh0Fa1vA",
    "outputId": "86ef8d70-ce6e-4ff1-bdc8-e4f483e96b34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard's index (no scaling) 0.22665080309339677\n",
      "Jaccard's index (scaling1) 0.6742992776098217\n"
     ]
    }
   ],
   "source": [
    "print(\"Jaccard's index (no scaling)\", jaccard_index(xglue_10k_freqs,clc_10k_freqs)[0])\n",
    "print(\"Jaccard's index (scaling1)\", jaccard_index(xglue_10k_freqs_norm1,clc_10k_freqs_norm1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "careful-modeling",
   "metadata": {
    "id": "RZ1jqRN68vA5"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "**XTREME**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "weekly-novel",
   "metadata": {
    "id": "BaBpRQVo81Aq"
   },
   "outputs": [],
   "source": [
    "#normalizing1:\n",
    "xtreme_10k_freqs_norm1, clc_10k_freqs_norm1=scaler1(xtreme_10k_freqs,clc_10k_freqs)\n",
    "df_clc_10k_freqs_norm1=pd.DataFrame.from_dict(clc_10k_freqs_norm1, orient='index')\n",
    "df_xtreme_10k_freqs_norm1=pd.DataFrame.from_dict(xtreme_10k_freqs_norm1, orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunrise-assault",
   "metadata": {
    "id": "j811szKG9enA"
   },
   "source": [
    "Jaccard's score between 100LC and XTREME:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "complete-cleveland",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QoiGPmJH9enB",
    "outputId": "20ddc86c-cef3-47c9-af61-efff1183e11e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard's index (no scaling) 0.46179006839131725\n",
      "Jaccard's index (scaling1) 0.775188919443282\n"
     ]
    }
   ],
   "source": [
    "print(\"Jaccard's index (no scaling)\", jaccard_index(xtreme_10k_freqs,clc_10k_freqs)[0])\n",
    "print(\"Jaccard's index (scaling1)\", jaccard_index(xtreme_10k_freqs_norm1,clc_10k_freqs_norm1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "going-average",
   "metadata": {
    "id": "3XPukFGuvN9w"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "**Mbert (wiki data)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "compliant-distributor",
   "metadata": {
    "id": "2bla1d-IvSrn"
   },
   "outputs": [],
   "source": [
    "#normalizing1:\n",
    "mbert_10k_freqs_norm1, clc_10k_freqs_norm1=scaler1(mbert_10k_freqs,clc_10k_freqs)\n",
    "df_clc_10k_freqs_norm1=pd.DataFrame.from_dict(clc_10k_freqs_norm1, orient='index')\n",
    "df_mbert_10k_freqs_norm1=pd.DataFrame.from_dict(mbert_10k_freqs_norm1, orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acute-contrast",
   "metadata": {
    "id": "XTkmvIfFw9UW"
   },
   "source": [
    "Jaccard's score between 100LC and MBERT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "stretch-music",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bjZNGNaew9UY",
    "outputId": "136b98d3-870b-480f-8e8d-1ab4fcc19d74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard's index (no scaling) 0.6730947955390335\n",
      "Jaccard's index (scaling1) 0.7104482110006572\n"
     ]
    }
   ],
   "source": [
    "print(\"Jaccard's index (no scaling)\", jaccard_index(mbert_10k_freqs,clc_10k_freqs)[0])\n",
    "print(\"Jaccard's index (scaling1)\", jaccard_index(mbert_10k_freqs_norm1,clc_10k_freqs_norm1)[0])Teddi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
